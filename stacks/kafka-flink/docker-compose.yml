version: "3"

networks:
  scada-demo:
    name: scada-demo
    driver: bridge

services:

  # ---------------
  # Confluent Kafka
  # ---------------
  # https://docs.confluent.io/platform/current/installation/docker/config-reference.html
  # https://gist.github.com/everpeace/7a317860cab6c7fb39d5b0c13ec2543e
  # https://github.com/framiere/a-kafka-story/blob/master/step14/docker-compose.yml
  kafka-zookeeper:
    image: confluentinc/cp-zookeeper:${CONFLUENT_VERSION}
    environment:
      ZOOKEEPER_CLIENT_PORT: ${PORT_KAFKA_ZOOKEEPER}
      KAFKA_OPTS: -Dzookeeper.4lw.commands.whitelist=ruok
    networks:
      - scada-demo

    # Define health check for Zookeeper.
    healthcheck:
      # https://github.com/confluentinc/cp-docker-images/issues/827
      test: ["CMD", "bash", "-c", "echo ruok | nc localhost ${PORT_KAFKA_ZOOKEEPER} | grep imok"]
      start_period: 3s
      interval: 2s
      timeout: 30s
      retries: 60

  kafka-broker:
    image: confluentinc/cp-kafka:${CONFLUENT_VERSION}
    ports:
      - "${PORT_KAFKA_BROKER_INTERNAL}:${PORT_KAFKA_BROKER_INTERNAL}"
      - "${PORT_KAFKA_BROKER_EXTERNAL}:${PORT_KAFKA_BROKER_EXTERNAL}"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: kafka-zookeeper:${PORT_KAFKA_ZOOKEEPER}
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:${PORT_KAFKA_BROKER_INTERNAL},EXTERNAL://0.0.0.0:${PORT_KAFKA_BROKER_EXTERNAL}
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-broker:${PORT_KAFKA_BROKER_INTERNAL},EXTERNAL://localhost:${PORT_KAFKA_BROKER_EXTERNAL}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - kafka-zookeeper
    networks:
      - scada-demo

    # Define health check for Kafka broker.
    healthcheck:
      #test: ps augwwx | egrep "kafka.Kafka"
      test: ["CMD", "nc", "-vz", "localhost", "${PORT_KAFKA_BROKER_INTERNAL}"]
      start_period: 3s
      interval: 0.5s
      timeout: 30s
      retries: 60

  # The Kafka schema registry as well as ksqlDB is not needed for this setup.
  #kafka-schema-registry:
  #  image: confluentinc/cp-schema-registry:${CONFLUENT_VERSION}
  #kafka-ksqldb:
  #  image: confluentinc/cp-ksqldb-server:${CONFLUENT_VERSION}


  # ------------
  # Apache Flink
  # ------------
  # https://ci.apache.org/projects/flink/flink-docs-master/docs/deployment/resource-providers/standalone/docker/#flink-with-docker-compose
  flink-jobmanager:
    image: flink:${FLINK_VERSION}
    ports:
      - "${PORT_FLINK_JOBMANAGER}:${PORT_FLINK_JOBMANAGER}"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
    networks:
      - scada-demo

    # Define health check for Apache Flink jobmanager.
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:${PORT_FLINK_JOBMANAGER}/overview" ]
      start_period: 3s
      interval: 0.5s
      timeout: 30s
      retries: 60

  flink-taskmanager:
    image: flink:${FLINK_VERSION}
    depends_on:
      - flink-jobmanager
    command: taskmanager
    deploy:
      replicas: 1
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2
    networks:
      - scada-demo


  # -------
  # CrateDB
  # -------
  cratedb:
    image: crate:${CRATEDB_VERSION}
    ports:
      - "${PORT_CRATEDB_HTTP}:${PORT_CRATEDB_HTTP}"
      - "${PORT_CRATEDB_POSTGRESQL}:${PORT_CRATEDB_POSTGRESQL}"
    environment:
      CRATE_HEAP_SIZE: 4g

    command: ["crate",
              "-Cdiscovery.type=single-node",
              "-Ccluster.routing.allocation.disk.threshold_enabled=false",
             ]
    networks:
      - scada-demo

    # Define health check for CrateDB.
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:${PORT_CRATEDB_HTTP}" ]
      start_period: 3s
      interval: 0.5s
      timeout: 30s
      retries: 60


  # -------
  # Bundler
  # -------
  # Wait for all defined services to be fully available by probing their health
  # status, even when using `docker compose up --detach`.
  # https://marcopeg.com/2019/docker-compose-healthcheck/
  start-dependencies:
    image: dadarek/wait-for-dependencies
    depends_on:
      kafka-broker:
        condition: service_healthy
      flink-jobmanager:
        condition: service_healthy
      cratedb:
        condition: service_healthy


  # -----
  # Tasks
  # -----

  # Create a Kafka topic for publishing messages.
  create-table:
    image: westonsteimel/httpie
    networks: [scada-demo]
    command: http "cratedb:${PORT_CRATEDB_HTTP}/_sql?pretty" stmt='CREATE TABLE "taxi_rides" ("payload" OBJECT(DYNAMIC))'
    deploy:
      replicas: 0

  # Create a CrateDB table to receive data.
  create-topic:
    image: confluentinc/cp-kafka:${CONFLUENT_VERSION}
    networks: [scada-demo]
    command: kafka-topics --bootstrap-server kafka-broker:${PORT_KAFKA_BROKER_INTERNAL} --create --replication-factor 1 --partitions 1 --topic rides
    deploy:
      replicas: 0

  # Drop database table in CrateDB.
  drop-table:
    image: westonsteimel/httpie
    networks: [scada-demo]
    command: http "cratedb:${PORT_CRATEDB_HTTP}/_sql?pretty" stmt='DROP TABLE "taxi_rides"'
    deploy:
      replicas: 0

  # Invoke HTTPie via Docker.
  httpie:
    image: westonsteimel/httpie
    networks: [scada-demo]
    deploy:
      replicas: 0

  # List running Flink jobs.
  list-jobs:
    image: flink:${FLINK_VERSION}
    networks: [scada-demo]
    command: flink list --jobmanager=flink-jobmanager:${PORT_FLINK_JOBMANAGER}
    deploy:
      replicas: 0

  # Publish data to Kafka topic.
  publish-data:
    image: confluentinc/cp-kafka:${CONFLUENT_VERSION}
    networks: [scada-demo]
    command: kafka-console-producer --bootstrap-server kafka-broker:${PORT_KAFKA_BROKER_INTERNAL} --topic rides
    deploy:
      replicas: 0

  # Submit Flink job.
  submit-job:
    image: flink:${FLINK_VERSION}
    networks: [scada-demo]
    command: >
      flink run
        --jobmanager=flink-jobmanager:${PORT_FLINK_JOBMANAGER}
        /${JARFILE}
          --kafka.servers kafka-broker:${PORT_KAFKA_BROKER_INTERNAL}
          --kafka.topic rides
          --crate.hosts cratedb:${PORT_CRATEDB_POSTGRESQL}
          --crate.table taxi_rides
    deploy:
      replicas: 0

  # Subscribe to Kafka topic.
  subscribe-topic:
    image: edenhill/kcat:${KCAT_VERSION}
    networks: [scada-demo]
    command: kcat -b kafka-broker -C -t rides -o end
    deploy:
      replicas: 0
