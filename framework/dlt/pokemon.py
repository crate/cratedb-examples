"""data load tool (dlt) â€” the open-source Python library for data loading

How to create a data loading pipeline with dlt and CrateDB in 3 seconds:

0. Configure `cratedb` destination in `.dlt/secrets.toml`.
  ```toml
  [destination.cratedb.credentials]
  host = "localhost"
  port = 5432
  username = "crate"
  password = ""
  ```

1. Write a pipeline script
>>> import dlt
>>> from dlt.sources.helpers import requests
>>> dlt.run(
...     data=requests.get("https://pokeapi.co/api/v2/pokemon/").json()["results"],
...     destination="cratedb",
...     dataset_name="doc",
...     table_name="pokemon")

2. Run your pipeline script
  > $ python pokemon.py

3. See and query your data with autogenerated Streamlit app
  > $ dlt pipeline dlt_pokemon show

Or start with our pipeline template with sample PokeAPI (pokeapi.co) data loaded to bigquery

  > $ dlt init pokemon bigquery

For more detailed info, see https://dlthub.com/docs/intro
"""


def main():
    import dlt
    import dlt_cratedb
    from dlt.sources.helpers import requests

    dlt.run(
        data=requests.get("https://pokeapi.co/api/v2/pokemon/").json()["results"],
        destination="cratedb",
        dataset_name="doc",
        table_name="pokemon")


if __name__ == "__main__":
    main()
