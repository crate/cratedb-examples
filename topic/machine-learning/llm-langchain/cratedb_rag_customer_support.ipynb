{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook shows how to use the CrateDB vector store functionality around FLOAT_VECTOR and KNN_MATCH. You will learn how to use it to create a retrieval augmented generation (RAG) pipeline."
   ],
   "metadata": {
    "id": "rUPQQ-jlMkUd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What is CrateDB?\n",
    "\n",
    "CrateDB is an open-source, distributed, and scalable SQL analytics database for storing and analyzing massive amounts of data in near real-time, even with complex queries. It is wire-compatible to PostgreSQL, based on Lucene, and inherits the shared-nothing distribution layer of Elasticsearch.\n",
    "\n",
    "This example uses the Python client driver for CrateDB."
   ],
   "metadata": {
    "id": "Pe-5yxFDMl0S"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting Started\n",
    "CrateDB supports storing vectors since version 5.5. You can leverage the fully managed service of CrateDB Cloud, or install CrateDB on your own, for example using Docker.\n",
    "\n",
    "```shell\n",
    "docker run --publish 4200:4200 --publish 5432:5432 --pull=always crate:latest -Cdiscovery.type=single-node\n",
    "```\n",
    "\n",
    "## Setup\n",
    "\n",
    "Install required Python packages, and import Python modules."
   ],
   "metadata": {
    "id": "rE-UtZJnMs2q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install -r requirements.txt"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJyP1GEXNHUy",
    "outputId": "9c62258f-f6a1-4578-ced4-40f15f586e9a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from pueblo.util.environ import getenvpass"
   ],
   "metadata": {
    "id": "VUNjBDrXNNoG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configure database settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CONNECTION_STRING = os.environ.get(\n",
    "    \"CRATEDB_CONNECTION_STRING\",\n",
    "    \"crate://crate@localhost/\",\n",
    ")\n",
    "\n",
    "# For CrateDB Cloud, use:\n",
    "# CONNECTION_STRING = os.environ.get(\n",
    "#     \"CRATEDB_CONNECTION_STRING\",\n",
    "#     \"crate://username:password@hostname/?ssl=true\",\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configure OpenAI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "getenvpass(\"OPENAI_API_KEY\", prompt=\"OpenAI API key:\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Patches\n",
    "Those can be removed again after they have been upstreamed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Bring this into the `crate-python` driver.\n",
    "from cratedb_toolkit.sqlalchemy.patch import patch_inspector\n",
    "patch_inspector()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create embeddings from dataset"
   ],
   "metadata": {
    "id": "Cd2BLNlReU01"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loader = CSVLoader(file_path=\"./sample_data/twitter_support_microsoft.csv\", encoding=\"utf-8\", csv_args={'delimiter': ','})\n",
    "data = loader.load()\n",
    "pages_text = [doc.page_content for doc in data]\n",
    "print(pages_text[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Po5rpReNuhn",
    "outputId": "84e363de-84be-4c96-d3b7-8c4561fd03db"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embeddings = OpenAIEmbeddings(deployment='my-embedding-model', chunk_size=1)\n",
    "pages_embeddings = embeddings.embed_documents(pages_text)"
   ],
   "metadata": {
    "id": "nWl5RSPjPgGv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write data to CrateDB\n",
    "\n",
    "The next step creates a dataframe that contains the text of the documents and their embeddings. The embeddings will be stored in CrateDB using FLOAT_VECTOR type."
   ],
   "metadata": {
    "id": "QhOU-4aXQkTX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(list(zip(pages_text, pages_embeddings)), columns=['text', 'embedding'])"
   ],
   "metadata": {
    "id": "r_I0dlUNQgKU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "engine = sa.create_engine(CONNECTION_STRING, echo=False)\n",
    "\n",
    "create_table = sa.text(\"CREATE TABLE IF NOT EXISTS text_data (text TEXT, embedding FLOAT_VECTOR(1536))\")\n",
    "with engine.connect() as con:\n",
    "     con.execute(create_table)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzsx_YdaV2et",
    "outputId": "221fe177-212e-4e74-9a26-e4d48d6eae3d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The text and embeddings are written to CrateDB database using CrateDB vector storage support:"
   ],
   "metadata": {
    "id": "r5MDKdW5Y_Um"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df.to_sql(name='text_data', con=engine, if_exists='append', index=False)\n",
    "df.head(5)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8pzKlr3uV3Ql",
    "outputId": "93566fa0-7ef4-44fd-e29e-23e7b29c645f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ask question\n",
    "Let's define our question and create an embedding using OpenAI embedding model:"
   ],
   "metadata": {
    "id": "GkAPZ55RZQ09"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "my_question = \"How to update shipping address on existing order in Microsoft Store?\"\n",
    "query_embedding = embeddings.embed_query(my_question)"
   ],
   "metadata": {
    "id": "InhR73isZJCB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find relevant context using similarity search\n",
    "\n",
    "The `knn_match (search_vector, query_vector, k) `function in CrateDB performs an approximate k-nearest neighbors (KNN) search within a dataset. KNN search involves finding the k data points that are most similar to a given query data point. We find the most similar vectors to our query vector using knn search capability in CrateDB:"
   ],
   "metadata": {
    "id": "6XnNZHI6ajaS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "knn_query = sa.text(\"\"\"SELECT text FROM text_data\n",
    "            WHERE knn_match(embedding, {0}, 2)\"\"\".format(query_embedding))\n",
    "documents=[]\n",
    "\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(knn_query)\n",
    "    for record in results:\n",
    "        documents.append(record[0])\n",
    "\n",
    "print(documents)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjLeMkwMagOf",
    "outputId": "2c92d6fc-22aa-4914-b58c-bbd3928108e1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Augment system prompt and query LLM"
   ],
   "metadata": {
    "id": "-j94BF-3e1Je"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "context = '---\\n'.join(documents)\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are customer support expert and get questions about Microsoft products and services.\n",
    "To answer question use the information from the context. Remove new line characters from the answer.\n",
    "If you don't find the relevant information there, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\"\"\"\n",
    "\n",
    "chat_completion = openai.chat.completions.create(model=\"gpt-4\",\n",
    "                                               messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                                                         {\"role\": \"user\", \"content\": my_question}])\n"
   ],
   "metadata": {
    "id": "IEuq9r2EaqUz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "chat_completion.choices[0].message.content"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "aQnmpCIZa13L",
    "outputId": "a10c71a7-a6c7-4f83-c069-df49703d4654"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
