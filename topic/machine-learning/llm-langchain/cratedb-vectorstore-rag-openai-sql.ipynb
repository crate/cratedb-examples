{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab24d5c7",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG) with CrateDB\n",
    "\n",
    "This notebook shows how to use the CrateDB vector store functionality around\n",
    "[`FLOAT_VECTOR`] and [`KNN_MATCH`]. You will learn how to use it to create a\n",
    "retrieval augmented generation (RAG) pipeline.\n",
    "\n",
    "\n",
    "## What is CrateDB?\n",
    "\n",
    "[CrateDB] is an open-source, distributed, and scalable SQL analytics database\n",
    "for storing and analyzing massive amounts of data in near real-time, even with\n",
    "complex queries. It is wire-compatible to PostgreSQL, based on [Lucene], and\n",
    "inherits the shared-nothing distribution layer of [Elasticsearch].\n",
    "\n",
    "This example uses the [Python client driver for CrateDB].\n",
    "\n",
    "\n",
    "[CrateDB]: https://github.com/crate/crate\n",
    "[Elasticsearch]: https://github.com/elastic/elasticsearch\n",
    "[`FLOAT_VECTOR`]: https://crate.io/docs/crate/reference/en/master/general/ddl/data-types.html#float-vector\n",
    "[`KNN_MATCH`]: https://crate.io/docs/crate/reference/en/master/general/builtins/scalar-functions.html#scalar-knn-match\n",
    "[Lucene]: https://github.com/apache/lucene\n",
    "[Python client driver for CrateDB]: https://crate.io/docs/python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1fd393",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "CrateDB supports storing vectors since version 5.5. You can leverage the fully managed service of\n",
    "[CrateDB Cloud], or install CrateDB on your own, for example using Docker.\n",
    "\n",
    "```shell\n",
    "docker run --publish 4200:4200 --publish 5432:5432 --pull=always crate:latest -Cdiscovery.type=single-node\n",
    "```\n",
    "\n",
    "[CrateDB Cloud]: https://console.cratedb.cloud/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c3e61",
   "metadata": {},
   "source": [
    "Install required Python packages, and import Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt\n",
    "\n",
    "# Note: If you are running in an environment like Google Colab, please use the absolute path of the requirements:\n",
    "#!pip install -r https://raw.githubusercontent.com/crate/cratedb-examples/main/topic/machine-learning/llm-langchain/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9b2d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# TODO: Bring this into the `crate-python` driver.\n",
    "from cratedb_toolkit.sqlalchemy.patch import patch_inspector\n",
    "patch_inspector()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211656e0",
   "metadata": {},
   "source": [
    "You need to provide an OpenAI API key, optionally using the environment variable `OPENAI_API_KEY`,\n",
    "or by defining it within an `.env` file.\n",
    "\n",
    "```shell\n",
    "export OPENAI_API_KEY=sk-YOUR_OPENAI_API_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87e5ab",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pueblo.util.environ import getenvpass\n",
    "\n",
    "getenvpass(\"OPENAI_API_KEY\", prompt=\"OpenAI API key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff97428",
   "metadata": {},
   "source": [
    "You also need to provide a connection string to your CrateDB database cluster,\n",
    "optionally using the environment variable `CRATEDB_CONNECTION_STRING`.\n",
    "\n",
    "This example uses a CrateDB instance on your workstation, which you can start by\n",
    "running [CrateDB using Docker]. Alternatively, you can also connect to a cluster\n",
    "running on [CrateDB Cloud].\n",
    "\n",
    "[CrateDB Cloud]: https://console.cratedb.cloud/\n",
    "[CrateDB using Docker]: https://crate.io/docs/crate/tutorials/en/latest/basic/index.html#docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e04e3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CONNECTION_STRING = os.environ.get(\n",
    "    \"CRATEDB_CONNECTION_STRING\",\n",
    "    \"crate://crate@localhost/\",\n",
    ")\n",
    "\n",
    "# For CrateDB Cloud, use:\n",
    "# CONNECTION_STRING = os.environ.get(\n",
    "#     \"CRATEDB_CONNECTION_STRING\",\n",
    "#     \"crate://username:password@hostname/?ssl=true&schema=langchain\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c9ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = \"\"\"\n",
    "# Alternatively, the connection string can be assembled from individual\n",
    "# environment variables.\n",
    "import os\n",
    "\n",
    "CONNECTION_STRING = CrateDBVectorSearch.connection_string_from_db_params(\n",
    "    driver=os.environ.get(\"CRATEDB_DRIVER\", \"crate\"),\n",
    "    host=os.environ.get(\"CRATEDB_HOST\", \"localhost\"),\n",
    "    port=int(os.environ.get(\"CRATEDB_PORT\", \"4200\")),\n",
    "    database=os.environ.get(\"CRATEDB_DATABASE\", \"langchain\"),\n",
    "    user=os.environ.get(\"CRATEDB_USER\", \"crate\"),\n",
    "    password=os.environ.get(\"CRATEDB_PASSWORD\", \"\"),\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44046423",
   "metadata": {},
   "source": [
    "## Step 1: Load PDF and split the data\n",
    "\n",
    "Let's use the white-paper [Time-series data in manufacturing] as a foundation for the upcoming\n",
    "explorations, to augment the LLM data. The paper provides a good overview about the database\n",
    "technologies for storing and analyzing time-series data.\n",
    "\n",
    "The data is split into chunks of 1,000 characters, with an overlap of 200 characters between\n",
    "the chunks, which helps to give better results by containing the context of the information\n",
    "between chunks:\n",
    "\n",
    "[Time-series data in manufacturing]: https://cratedb.com/resources/white-papers/lp-wp-time-series-data-manufacturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5e7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"https://github.com/crate/cratedb-datasets/raw/main/machine-learning/fulltext/White%20paper%20-%20Time-series%20data%20in%20manufacturing.pdf\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "pages = loader.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad4eb02",
   "metadata": {},
   "source": [
    "## Step 2: Store embeddings\n",
    "\n",
    "This section explains how to store text and embeddings into CrateDB using SQL and pandas,\n",
    "without using the LangChain integration. This can be beneficial if you have special\n",
    "requirements regarding security inside the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a13ffb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ WHITE PAPER   \\n \\n \\n \\nTime-series data  i...</td>\n",
       "      <td>[0.0025093274553031246, -0.02196431773679507, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://crate.io   |  office@crate.io  |  +43 ...</td>\n",
       "      <td>[-0.0049216739619637, -0.010619178696718409, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://crate.io   |  office@crate.io  |  +43 ...</td>\n",
       "      <td>[-0.022959793496217757, 0.0031425609019670345,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>processed. The great advantages in data techno...</td>\n",
       "      <td>[-0.008236182477236282, -0.011472808604225981,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>due to the expansion of the IoT. Something is ...</td>\n",
       "      <td>[0.007639478261629491, -0.022254722218927096, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  / WHITE PAPER   \\n \\n \\n \\nTime-series data  i...   \n",
       "1  https://crate.io   |  office@crate.io  |  +43 ...   \n",
       "2  https://crate.io   |  office@crate.io  |  +43 ...   \n",
       "3  processed. The great advantages in data techno...   \n",
       "4  due to the expansion of the IoT. Something is ...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0025093274553031246, -0.02196431773679507, ...  \n",
       "1  [-0.0049216739619637, -0.010619178696718409, 0...  \n",
       "2  [-0.022959793496217757, 0.0031425609019670345,...  \n",
       "3  [-0.008236182477236282, -0.011472808604225981,...  \n",
       "4  [0.007639478261629491, -0.022254722218927096, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "pages_text = [doc.page_content for doc in pages]\n",
    "pages_embeddings = embeddings.embed_documents(pages_text)\n",
    "\n",
    "# The next step creates a dataframe that contains the text of the documents and their embeddings. \n",
    "df = pd.DataFrame(list(zip(pages_text, pages_embeddings)), columns=['text', 'embedding'])\n",
    "\n",
    "# The embeddings will be stored in CrateDB using the FLOAT_VECTOR type.\n",
    "engine = sa.create_engine(CONNECTION_STRING, echo=False)\n",
    "with engine.connect() as connection:\n",
    "\n",
    "    # Create database table.\n",
    "    connection.execute(sa.text(\"CREATE TABLE IF NOT EXISTS text_data (text TEXT, embedding FLOAT_VECTOR(1536));\"))\n",
    "\n",
    "    # Write text and embeddings to CrateDB database.\n",
    "    df.to_sql(name=\"text_data\", con=connection, if_exists=\"append\", index=False)\n",
    "    connection.execute(sa.text(\"REFRESH TABLE text_data;\"))\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634c5297",
   "metadata": {},
   "source": [
    "## Step 3: Retrieve\n",
    "\n",
    "The `knn_match(search_vector, query_vector, k)` function in CrateDB performs an approximate k-nearest\n",
    "neighbors (KNN) search within a dataset. KNN search involves finding the k data points that are most\n",
    "similar to a given query data point per shard of the table.\n",
    "\n",
    "Therefore, `ORDER BY _score` and `LIMIT` to 4, to achieve a total amount of four relevant documents\n",
    "that will provide the context for the prompt.\n",
    "\n",
    "Find the most similar vectors to the input query vector, using knn search capabilities in CrateDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c97a515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Define the question and create an embedding using the OpenAI embedding model.\n",
    "my_question = \"What is the difference between time series and NoSQL databases?\"\n",
    "query_embedding = embeddings.embed_query(my_question)\n",
    "\n",
    "knn_query = sa.text(\"SELECT text FROM text_data WHERE knn_match(embedding, {0}, 4) ORDER BY _score DESC LIMIT 4\".format(query_embedding))\n",
    "documents=[]\n",
    "\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(knn_query)\n",
    "    for record in results:\n",
    "        documents.append(record[0])\n",
    "        \n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d84078",
   "metadata": {},
   "source": [
    "## Step 4: Generate\n",
    "\n",
    "The goal is to distill the retrieved documents into an answer using an LLM/Chat model,\n",
    "for example `gpt-3.5-turbo`.\n",
    "\n",
    "Create a short system prompt to instruct the LLM how to answer the question, and send\n",
    "similar documents alongside the user's question as additional context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "528fc11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series databases and NoSQL databases are two distinct types of databases with different characteristics and use cases.\n",
      "\n",
      "Time series databases are designed specifically to handle time-stamped data efficiently. They excel at managing large volumes of data points with high ingestion and query rates. Time series databases optimize for storing and retrieving data based on time, allowing for fast and efficient retrieval of time-based data. They often provide specialized functions and features for time series analysis, such as downsampling, interpolation, and aggregation.\n",
      "\n",
      "On the other hand, NoSQL databases are a broad category of databases that do not adhere to the traditional relational database management system (RDBMS) model. NoSQL databases are designed to handle unstructured or semi-structured data. They prioritize scalability, high availability, and flexible data models. NoSQL databases use different data models, such as key-value, document, column-family, and graph, to suit different types of data and applications.\n",
      "\n",
      "While time series databases are optimized for handling time-stamped data and provide specific features for time series analysis, NoSQL databases are more general-purpose and can handle a wide range of data types and use cases. NoSQL databases offer scalability and flexibility at the expense of some specialized time series functionality.\n",
      "\n",
      "In summary, the main difference between time series and NoSQL databases lies in their design focus and capabilities. Time series databases are specialized for efficient management and analysis of time-stamped data, while NoSQL databases provide scalability and flexibility for various data types and use cases.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Concatenate the found documents into the context that will be provided in the system prompt\n",
    "context = '---\\n'.join(doc for doc in documents)\n",
    "\n",
    "# Give instructions and context in the system prompt\n",
    "system_prompt = f\"\"\"\n",
    "You are a time series expert and get questions from the user covering the area of time series databases and time series use cases. \n",
    "Please answer the users question in the language it was asked in. \n",
    "Please only use the following context to answer the question, if you don't find the relevant information there, say \"I don't know\".\n",
    "\n",
    "Context: \n",
    "{context}\"\"\"\n",
    "\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": my_question}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
