{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5170c824",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Timeseries QA with LLMs & Manuals\n",
    "\n",
    "Welcome to this **hands-on workshop** where we explore how to combine **LLMs (Large Language Models)** with **machine telemetry data** and **equipment manuals** for smart diagnostics and interactive data exploration.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Workshop Goals\n",
    "\n",
    "By the end of this session, you'll be able to:\n",
    "\n",
    "- ‚úÖ **Query timeseries data** using natural language\n",
    "- ‚úÖ **Detect anomalies** using both data and manual thresholds\n",
    "- ‚úÖ **Interpret machine behavior** by combining real-time metrics with context from manuals\n",
    "- ‚úÖ **Generate SQL and visualizations** with the help of an LLM\n",
    "- ‚úÖ **Explain telemetry results** in plain English\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Why This Matters\n",
    "\n",
    "Modern machines generate a huge volume of telemetry data (vibration, temperature, speed, etc.). Understanding this data is critical for:\n",
    "\n",
    "- üõë **Detecting anomalies before they cause failures**\n",
    "- üîç **Explaining why something is behaving abnormally**\n",
    "- üß∞ **Making maintenance more proactive and data-driven**\n",
    "\n",
    "But reading raw data isn't enough...\n",
    "\n",
    "That's why this notebook shows how **AI assistants can help domain experts and analysts** by combining:\n",
    "\n",
    "> üìä **Telemetry data** (from CrateDB)  \n",
    "> üìò **Manuals and expert context** (stored in SQL)  \n",
    "> üí¨ **Natural language** (as the interface)\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ What You'll Build\n",
    "\n",
    "Over the course of this workshop, you'll create a system that can:\n",
    "\n",
    "- Load and explore machine telemetry stored in CrateDB\n",
    "- Ask questions like:\n",
    "  - _‚ÄúIs machine 5 overheating?‚Äù_\n",
    "  - _‚ÄúWhat should I do if machine 3 has an anomaly?‚Äù_\n",
    "- Generate relevant SQL queries using an LLM (OpenAI)\n",
    "- Combine SQL results with manual guidance to form a natural-language answer\n",
    "\n",
    "All of this will run **in a single Jupyter notebook** ‚Äî no frontend or backend code needed.\n",
    "\n",
    "---\n",
    "\n",
    "Let‚Äôs get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cea826",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Installation \n",
    "\n",
    "üõ†Ô∏è Setup and Installation\n",
    "In this step, we install all required Python packages to run the workshop.\n",
    "Google Colab already includes many by default, but we ensure compatibility and version alignment here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc578ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install pandas matplotlib openai sqlalchemy-cratedb python-dotenv ipython-sql\n",
    "\n",
    "# CrateDB Client\n",
    "!pip install crate\n",
    "\n",
    "# Optional: Install tqdm for nicer loading bars if needed\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9543b2",
   "metadata": {},
   "source": [
    "### üîê Setup: Add the OpenAI API Key\n",
    "\n",
    "To use the assistant and generate SQL from natural language, you need to provide access to the OpenAI API.\n",
    "\n",
    "> üí° For this workshop, we've provided a shared API key. Please **run the cell below**, and you‚Äôll be prompted to enter the key **once**. This will be securely stored in your Colab session and never visible to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ef442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Helper to load and validate OpenAI client from env/Colab/manual\n",
    "def load_openai_client():\n",
    "    import os\n",
    "    import re\n",
    "    from getpass import getpass\n",
    "\n",
    "    # Try Colab secrets\n",
    "    openai_api_key = None\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
    "        if openai_api_key:\n",
    "            print(\"‚úÖ Loaded OpenAI key from Colab secrets.\")\n",
    "    except ImportError:\n",
    "        pass  # Not running in Colab\n",
    "\n",
    "    # Try .env or system environment\n",
    "    if not openai_api_key:\n",
    "        try:\n",
    "            from dotenv import load_dotenv\n",
    "            load_dotenv()\n",
    "            openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "            if openai_api_key:\n",
    "                print(\"‚úÖ Loaded OpenAI key from .env or system environment.\")\n",
    "        except ImportError:\n",
    "            pass\n",
    "\n",
    "    # Prompt if still not set\n",
    "    if not openai_api_key:\n",
    "        print(\"‚ùó No OpenAI API key found. Please enter it manually.\")\n",
    "        openai_api_key = input(\"üîë Enter your OpenAI API key: \").strip()\n",
    "\n",
    "    # Final check before returning client\n",
    "    if not openai_api_key:\n",
    "        raise ValueError(\"‚ùå OpenAI API key is missing. Cannot continue.\")\n",
    "\n",
    "    # Create OpenAI client\n",
    "    from openai import OpenAI\n",
    "    return OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c723b",
   "metadata": {},
   "source": [
    "## Step 2: Generate and Store Synthetic Timeseries Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157242c8",
   "metadata": {},
   "source": [
    "### Connect to CrateDB\n",
    "\n",
    "\n",
    "For this workshop, we‚Äôll use **CrateDB** as our database to store both:\n",
    "\n",
    "- üìà **Timeseries telemetry data** (e.g., vibration, temperature, rotations)\n",
    "- üìò **Machine manuals** (e.g., anomaly thresholds, emergency protocols)\n",
    "\n",
    "CrateDB is a distributed SQL database optimized for **real-time analytics on machine data and IoT workloads**. It blends the scalability of NoSQL with the familiarity and power of SQL ‚Äî making it ideal for hybrid scenarios like combining sensor readings with structured documents.\n",
    "\n",
    "In this notebook, we‚Äôll use CrateDB to:\n",
    "\n",
    "- Store synthetic telemetry data across multiple machines\n",
    "- Store matching operational manuals per machine\n",
    "- Use natural language to **query both datasets together**\n",
    "- Detect anomalies, extract insights, and generate contextual diagnostics\n",
    "\n",
    "You can use **CrateDB Cloud** to get started without any setup:\n",
    "üîó [Launch a free cluster on CrateDB Cloud](https://console.cratedb.cloud/)\n",
    "\n",
    "Alternatively, you can also run CrateDB locally using Docker.\n",
    "\n",
    "Let‚Äôs connect and load our first dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "\n",
    "# Option 1: CrateDB Cloud (Update or set via CRATEDB_CONNECTION_STRING env variable)\n",
    "CONNECTION_STRING = os.environ.get(\n",
    "    \"CRATEDB_CONNECTION_STRING\",\n",
    "    \"crate://USER:PASSWORD@CRATEDB_HOST/?ssl=true\"\n",
    ")\n",
    "\n",
    "# Option 2: Localhost setup\n",
    "# CONNECTION_STRING = os.environ.get(\"CRATEDB_CONNECTION_STRING\", \"crate://crate@localhost/\")\n",
    "\n",
    "# Try to connect\n",
    "try:\n",
    "    engine = sa.create_engine(CONNECTION_STRING)\n",
    "    connection = engine.connect()\n",
    "    \n",
    "    # Run a simple query to validate connection\n",
    "    result = pd.read_sql(\"SELECT mountain FROM sys.summits LIMIT 1\", con=engine)\n",
    "    print(\"‚úÖ Successfully connected to CrateDB!\")\n",
    "    print(\"Sample query result from sys.summits:\", result.iloc[0]['mountain'])\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Failed to connect to CrateDB. Please check your connection string.\")\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c1726",
   "metadata": {},
   "source": [
    "### Define the Table Schema in CrateDB\n",
    "\n",
    "Before inserting data, we explicitly define the motor_readings table in CrateDB. This ensures consistent data types and structure, which is especially important when working in production environments or collaborating across teams.\n",
    "\n",
    "The table will store telemetry for each machine, including timestamped readings for vibration, temperature, and rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856582bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# Define the CREATE TABLE statement\n",
    "create_table_sql = text(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS motor_readings (\n",
    "    machine_id INTEGER,\n",
    "    timestamp TIMESTAMP WITHOUT TIME ZONE,\n",
    "    vibration DOUBLE PRECISION,\n",
    "    temperature DOUBLE PRECISION,\n",
    "    rotations DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "try:\n",
    "    connection.execute(create_table_sql)\n",
    "    print(\"‚úÖ Table 'motor_readings' created (if not already existing).\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Failed to create table.\")\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaebedc",
   "metadata": {},
   "source": [
    "### Generate & Load Timeseries Data\n",
    "\n",
    "Let‚Äôs generate synthetic telemetry data for 10 machines and store it in CrateDB under the table motor_readings.\n",
    "This table will serve as the base for all LLM queries and visual analytics in the next steps.\n",
    "\n",
    "You can modify the number of machines, simulation days, or reading frequency by adjusting the configuration block below.\n",
    "This gives you full control over the size and granularity of your synthetic timeseries dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8084239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "num_machines = 10       # Number of machines to simulate\n",
    "days = 30               # Number of days to simulate\n",
    "freq_minutes = 15       # Frequency of readings (in minutes)\n",
    "\n",
    "# --- Data Generation ---\n",
    "def generate_timeseries_data(num_machines, days, freq_minutes):\n",
    "    total_intervals = int((24 * 60 / freq_minutes) * days)\n",
    "    timestamps = [datetime.datetime.now() - datetime.timedelta(minutes=freq_minutes * i) for i in range(total_intervals)]\n",
    "    data = []\n",
    "\n",
    "    for machine_id in range(num_machines):\n",
    "        for t in timestamps:\n",
    "            vibration = np.round(np.random.normal(1.0, 0.2), 4)\n",
    "            temperature = np.round(np.random.normal(45, 2.5), 2)\n",
    "            rotations = np.round(np.random.normal(1600, 30), 2)\n",
    "            data.append([t, vibration, temperature, rotations, machine_id])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=[\"timestamp\", \"vibration\", \"temperature\", \"rotations\", \"machine_id\"])\n",
    "    return df\n",
    "\n",
    "# --- Generate & Preview ---\n",
    "df_ts = generate_timeseries_data(num_machines, days, freq_minutes)\n",
    "print(f\"‚úÖ Generated {len(df_ts)} rows of synthetic timeseries data.\")\n",
    "\n",
    "# --- Load to CrateDB ---\n",
    "df_ts.to_sql(\"motor_readings\", con=engine, if_exists=\"replace\", index=False)\n",
    "print(\"‚úÖ Data loaded into CrateDB table 'motor_readings'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e73b260",
   "metadata": {},
   "source": [
    "## Step 3: Previewing and Exploring the Data\n",
    "\n",
    "### Explore the Timeseries Data in CrateDB\n",
    "Now that we‚Äôve generated and loaded our synthetic telemetry data, let‚Äôs run some SQL queries to explore it.\n",
    "We‚Äôll inspect the table structure, check how many rows were inserted, and preview a few example records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Count total records\n",
    "df_count = pd.read_sql(\"SELECT COUNT(*) as total_rows FROM motor_readings\", con=engine)\n",
    "print(f\"üî¢ Total rows in 'motor_readings': {df_count.iloc[0]['total_rows']}\")\n",
    "\n",
    "# Query: Preview 5 sample rows (formatted timestamps)\n",
    "query_preview = \"\"\"\n",
    "SELECT \n",
    "    TO_CHAR(timestamp, 'YYYY-MM-DD HH24:MI:SS') AS ts,\n",
    "    vibration,\n",
    "    temperature,\n",
    "    rotations,\n",
    "    machine_id\n",
    "FROM motor_readings\n",
    "ORDER BY ts DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "df_preview = pd.read_sql(query_preview, con=engine)\n",
    "print(\"üëÄ Sample records:\")\n",
    "df_preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844ba9d5",
   "metadata": {},
   "source": [
    "### Optional Explore Distinct Machines and Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed5662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query distinct machines and formatted date range\n",
    "df_overview = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        machine_id AS unique_machines,\n",
    "        TO_CHAR(MIN(timestamp), 'YYYY-MM-DD HH24:MI:SS') AS start_time,\n",
    "        TO_CHAR(MAX(timestamp), 'YYYY-MM-DD HH24:MI:SS') AS end_time\n",
    "    FROM motor_readings\n",
    "    GROUP by unique_machines\n",
    "    ORDER BY unique_machines\n",
    "\"\"\", con=engine)\n",
    "\n",
    "print(\"üìÖ Data coverage overview:\")\n",
    "df_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02d28a",
   "metadata": {},
   "source": [
    "## Step 4: Natural Language Querying with an LLM (Table-Augmented Generation)\n",
    "\n",
    "### Ask Questions in Natural Language\n",
    "In this step, we use an LLM to convert plain-language questions into SQL queries and run them against our timeseries data in CrateDB.\n",
    "This is an example of **Table-Augmented Generation (TAG)** ‚Äî combining large language models with structured data.\n",
    "\n",
    "You‚Äôll be able to ask questions like:\n",
    "\t‚Ä¢\t‚ÄúWhat is the average rotation for machine 3?‚Äù\n",
    "\t‚Ä¢\t‚ÄúWhen was the last anomaly for machine 5?‚Äù\n",
    "\t‚Ä¢\t‚ÄúHow many temperature spikes were there last week?‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6289ccfc",
   "metadata": {},
   "source": [
    "### Helper\n",
    "**Fetch the column names and data types for a given table from CrateDB's system catalog.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table schema (columns and types) from CrateDB\n",
    "def fetch_table_schema(table_name):\n",
    "    query = f\"\"\"\n",
    "    SELECT column_name, data_type\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_name = '{table_name}'\n",
    "    ORDER BY ordinal_position\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_sql(query, con=engine)\n",
    "        schema_text = f\"Table: {table_name}\\nColumns:\\n\"\n",
    "        for _, row in df.iterrows():\n",
    "            schema_text += f\"- {row['column_name']} ({row['data_type']})\\n\"\n",
    "        return schema_text\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching schema for table '{table_name}':\", e)\n",
    "        return f\"Error fetching schema for {table_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede9c5b1",
   "metadata": {},
   "source": [
    "### Define Prompt Template \n",
    "This uses the OpenAI API to convert the natural language question into an SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101bdcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Create OpenAI client using environment variable\n",
    "openai_client = load_openai_client()\n",
    "\n",
    "# Create a natural language ‚Üí SQL prompt with real schema\n",
    "def nl_to_sql_prompt(question, table_name=\"motor_readings\"):\n",
    "    # Dynamically fetch schema\n",
    "    schema_description = fetch_table_schema(table_name)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a CrateDB SQL expert. Generate a SQL query using the following table schema:\n",
    "\n",
    "{schema_description}\n",
    "\n",
    "Assume an **anomaly** is defined as:\n",
    "vibration > 1.5 OR temperature > 80 OR rotations > 500\n",
    "\n",
    "This definition is for reference only ‚Äî do not apply anomaly filters unless the user‚Äôs question explicitly asks about anomalies.\n",
    "\n",
    "Rules:\n",
    "- Always include the 'timestamp' column in the SELECT clause for any question involving:\n",
    "  - plotting\n",
    "  - visualizations\n",
    "  - trends\n",
    "  - over time\n",
    "  - per day / week / hour\n",
    "- Only exclude 'timestamp' for pure aggregations (e.g., total counts without time).\n",
    "- If using date intervals, always write them as strings, e.g. INTERVAL '7 days', not INTERVAL 7 DAYS.\n",
    "- If using an aggregation function (e.g., MAX, AVG) with other fields, include a proper GROUP BY clause.\n",
    "- Use SQL syntax compatible with CrateDB.\n",
    "- Do not include any markdown formatting (like ```sql).\n",
    "\n",
    "User question:\n",
    "\\\"{question}\\\"\n",
    "\"\"\"\n",
    "\n",
    "# Run prompt and clean result\n",
    "def get_sql_from_llm(question, table_name=\"motor_readings\"):\n",
    "    prompt = nl_to_sql_prompt(question, table_name)\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that only outputs SQL queries compatible with CrateDB.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "    raw_sql = response.choices[0].message.content.strip()\n",
    "    cleaned_sql = re.sub(r\"```sql|```\", \"\", raw_sql).strip()\n",
    "    return cleaned_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a68349",
   "metadata": {},
   "source": [
    "### Code Cell: Ask a Question ‚Üí Run SQL ‚Üí Show Result\n",
    "You can customize the question below to ask anything about the timeseries data using plain English.\n",
    "\n",
    "The assistant will translate your question into SQL, run it on the `motor_readings` table, and return the result.\n",
    "\n",
    "Example questions (copy and paste into the input box below):\n",
    "- ```What is the average temperature for machine 2?```\n",
    "- ```When was the last recorded anomaly?```\n",
    "- ```How many readings had a vibration greater than 1.5?```\n",
    "- ```What was the number of anomalies per machine in last 48 hours?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b72ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question in natural language\n",
    "\n",
    "question = \"What was the average rotation for machine 3 the last week?\"\n",
    "# question = \"When was the last recorded anomaly?\"\n",
    "# question = \"How many readings had a vibration greater than 1.5?\"\n",
    "# question = \"What was the number of anomalies per machine in last 48 hours?\"\n",
    "\n",
    "# Convert to SQL\n",
    "sql_query = get_sql_from_llm(question)\n",
    "\n",
    "# Collect and format output in a single list\n",
    "output = []\n",
    "output.append(\"üß† Generated SQL:\")\n",
    "output.append(sql_query)\n",
    "\n",
    "try:\n",
    "    df_result = pd.read_sql(sql_query, con=engine)\n",
    "    output.append(\"‚úÖ Query executed. Result:\")\n",
    "    output.append(df_result.to_string(index=False))  # One box output\n",
    "except Exception as e:\n",
    "    output.append(\"‚ùå Error running query:\")\n",
    "    output.append(str(e))\n",
    "\n",
    "# Print all in one block\n",
    "print(\"\\n\".join(output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26477c0b",
   "metadata": {},
   "source": [
    "## Step 5: Visualizing Timeseries Data with Natural Language\n",
    "\n",
    "In this step, we use the assistant to convert a natural language question into SQL ‚Äî but instead of just showing a table, we‚Äôll visualize the result using Matplotlib.\n",
    "\n",
    "This lets you:\n",
    "- Plot machine readings over time\n",
    "- Compare metrics like vibration, temperature, and rotations\n",
    "- Quickly identify anomalies or trends\n",
    "\n",
    "Example questions:\n",
    "\n",
    "- `Show temperature and vibration for machine 2 over time.`\n",
    "- `Plot the average rotation per machine.`\n",
    "- `Show the number of anomalies per day.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f870d7f",
   "metadata": {},
   "source": [
    "### Ask a Question ‚Üí LLM Generates SQL ‚Üí Plot with Matplotlib\n",
    "\n",
    "We‚Äôll use the same get_sql_from_llm() function, then add a logic layer to check if the result has a timestamp column (for time-based plotting). \n",
    "\n",
    "The assistant will generate SQL and visualize the result as a time-series chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fee9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Step 1: Ask a visualization-friendly question\n",
    "question = \"Show temperature, rotations and vibration for machines 2 last monday.\"\n",
    "# question = \"Show average temperature, rotations and vibration for machine 2 last monday.\"\n",
    "\n",
    "# Step 2: Get SQL from LLM\n",
    "sql_query = get_sql_from_llm(question)\n",
    "print(\"üß† Generated SQL:\\n\", sql_query)\n",
    "\n",
    "# Step 3: Run the query\n",
    "try:\n",
    "    df_result = pd.read_sql(sql_query, con=engine)\n",
    "    print(\"‚úÖ Query returned\", len(df_result), \"rows.\")\n",
    "    \n",
    "    # Step 4: Try to plot if timestamp column is present\n",
    "    if \"timestamp\" in df_result.columns:\n",
    "        # Ensure timestamp is datetime and sorted (handle epoch ms)\n",
    "        df_result = df_result.sort_values(\"timestamp\")\n",
    "\n",
    "        # Convert epoch millis to datetime if needed\n",
    "        if df_result[\"timestamp\"].dtype in [\"int64\", \"float64\"]:\n",
    "            df_result[\"timestamp\"] = pd.to_datetime(df_result[\"timestamp\"], unit=\"ms\")\n",
    "        else:\n",
    "            df_result[\"timestamp\"] = pd.to_datetime(df_result[\"timestamp\"])\n",
    "\n",
    "        df_result.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "        # Plot numeric columns\n",
    "        fig, ax = plt.subplots(figsize=(14, 5))\n",
    "        df_result.plot(ax=ax, title=question)\n",
    "\n",
    "        # Format x-axis for better readability\n",
    "        ax.set_xlabel(\"Timestamp\")\n",
    "        ax.set_ylabel(\"Value\")\n",
    "        ax.grid(True)\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d\\n%H:%M'))\n",
    "\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No 'timestamp' column in result ‚Äî skipping visualization.\")\n",
    "        print(\"Tip: Ask a time-based question like '...over time' or 'per day' to enable plotting.\")\n",
    "        display(df_result)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error during SQL execution or plotting:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f61529",
   "metadata": {},
   "source": [
    "## Step 6: Integrate Machine Manuals into the QA Pipeline\n",
    "\n",
    "We dynamically generate fictional manuals for each machine based on the IDs in `motor_readings`.\n",
    "\n",
    "Each manual includes:\n",
    "- Operational limits\n",
    "- Maintenance schedules\n",
    "- Emergency protocols\n",
    "- Manufacturer and contact info\n",
    "\n",
    "This ensures the manual data matches whatever telemetry data has been created, even if someone customized the setup earlier.\n",
    "\n",
    "We store the results in a CrateDB table: `machine_manuals`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# === Configuration ===\n",
    "include_branding = True\n",
    "include_contact_info = True\n",
    "\n",
    "brands = [\"AtlasTech\", \"RotoFlow\", \"MechAxis\", \"IndustraCore\"]\n",
    "models = [\"VX100\", \"MX200\", \"TQ350\", \"RG450\"]\n",
    "year_range = list(range(2017, 2023))\n",
    "\n",
    "# === Load unique machine IDs from CrateDB ===\n",
    "machine_ids = pd.read_sql(\"SELECT DISTINCT machine_id FROM motor_readings\", con=engine)\n",
    "machine_ids = machine_ids[\"machine_id\"].tolist()\n",
    "\n",
    "def generate_manual(machine_id):\n",
    "    brand = random.choice(brands)\n",
    "    model = random.choice(models)\n",
    "    year = random.choice(year_range)\n",
    "\n",
    "    vib_max = round(random.uniform(1.2, 1.6), 2)\n",
    "    temp_max = round(random.uniform(65, 75), 1)\n",
    "    rpm_max = random.randint(1550, 1650)\n",
    "\n",
    "    # Build optional blocks\n",
    "    branding_section = \"\"\n",
    "    if include_branding:\n",
    "        branding_section = f\"\"\"**Manufacturer:** {brand}\n",
    "**Model:** {model}\n",
    "**Year of Installation:** {year}\"\"\"\n",
    "\n",
    "    contact_section = \"\"\n",
    "    if include_contact_info:\n",
    "        contact_section = f\"\"\"**Contact:**\n",
    "- Support: support@{brand.lower()}.com\n",
    "- Manual Version: 1.0\"\"\"\n",
    "\n",
    "    # Build the full manual string\n",
    "    content = f\"\"\"\n",
    "üõ†Ô∏è Machine Manual ‚Äî ID: {machine_id}\n",
    "\n",
    "{branding_section}\n",
    "\n",
    "---\n",
    "\n",
    "**Operational Limits:**\n",
    "- Max Vibration: {vib_max} units\n",
    "- Max Temperature: {temp_max}¬∞C\n",
    "- Max RPM: {rpm_max} rotations/min\n",
    "\n",
    "**Anomaly Detection:**\n",
    "- Vibration > {vib_max} may indicate imbalance or bearing issues\n",
    "- Temperature > {temp_max} may suggest overheating\n",
    "- RPM deviations > ¬±100 RPM require inspection\n",
    "\n",
    "---\n",
    "\n",
    "**Maintenance Schedule:**\n",
    "- Weekly: Inspect vibration and temperature logs\n",
    "- Monthly: Lubricate bearings and check alignment\n",
    "- Quarterly: Full motor calibration and safety check\n",
    "\n",
    "**Emergency Protocol:**\n",
    "If vibration exceeds {vib_max + 0.2} or temperature exceeds {temp_max + 5}:\n",
    "1. Immediately reduce load\n",
    "2. Shut down the motor if anomaly persists for >5 mins\n",
    "3. Notify operations lead and schedule maintenance\n",
    "\n",
    "---\n",
    "\n",
    "{contact_section}\n",
    "\"\"\".strip()\n",
    "\n",
    "    return {\n",
    "        \"machine_id\": machine_id,\n",
    "        \"manual\": content\n",
    "    }\n",
    "\n",
    "# Generate manuals for all machine IDs found\n",
    "manuals = [generate_manual(mid) for mid in machine_ids]\n",
    "df_manuals = pd.DataFrame(manuals)\n",
    "\n",
    "# Store in CrateDB\n",
    "df_manuals.to_sql(\"machine_manuals\", con=engine, if_exists=\"replace\", index=False)\n",
    "print(f\"‚úÖ Stored manuals for {len(df_manuals)} machines in 'machine_manuals'.\")\n",
    "_ = connection.execute(sa.text(\"REFRESH TABLE machine_manuals;\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1576cf",
   "metadata": {},
   "source": [
    "### View a Random Machine Manual\n",
    "\n",
    "Below is a randomly selected machine manual from the `machine_manuals` table.  \n",
    "Each manual includes operational guidelines, maintenance schedules, and emergency protocols ‚Äî all of which can be referenced by the assistant in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb403cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Step 1: Get machine IDs\n",
    "machine_ids = pd.read_sql(\"SELECT DISTINCT machine_id FROM machine_manuals\", con=engine)[\"machine_id\"].tolist()\n",
    "\n",
    "# Step 2: Choose one at random\n",
    "random_id = random.choice(machine_ids)\n",
    "\n",
    "# Step 3: Load manual content\n",
    "manual = pd.read_sql(f\"SELECT * FROM machine_manuals WHERE machine_id = {random_id}\", con=engine)\n",
    "manual_text = manual.iloc[0][\"manual\"]\n",
    "\n",
    "# Step 4: Display in scrollable, formatted box\n",
    "display(HTML(f\"\"\"\n",
    "<h4>üìò Manual for Machine ID: {random_id}</h4>\n",
    "<div style=\"border:1px solid #ccc; padding:10px; max-height:400px; overflow:auto; font-family:monospace; white-space:pre-wrap;\">\n",
    "{manual_text}\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b80fc",
   "metadata": {},
   "source": [
    "## Step 7: Context-Aware Assistant Using Data + Manuals\n",
    "\n",
    "Our assistant now has access to both telemetry (`motor_readings`) and manual guidance (`machine_manuals`).\n",
    "\n",
    "This allows it to:\n",
    "- Detect anomalies\n",
    "- Reference emergency protocols or limits\n",
    "- Provide maintenance guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd7b2a",
   "metadata": {},
   "source": [
    "### Assistant Logic to Merge Data + Manuals\n",
    "\n",
    "This code will:\n",
    "- Send the user‚Äôs question to the LLM\n",
    "- Let the LLM generate up to two SQL queries (one per table)\n",
    "- Run those queries\n",
    "- Return a natural-language answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f5dd2",
   "metadata": {},
   "source": [
    "In order to keep things understanable we will make different modules. \n",
    "\n",
    "#### Helper Functions\n",
    "\n",
    "**Function Responsibility Table**\n",
    "\n",
    "| Function                     | Description                                                                 |\n",
    "|-----------------------------|-----------------------------------------------------------------------------|\n",
    "| `extract_sql_blocks()`      | Pulls out `SQL 1`, `SQL 2`, and `Answer:` from LLM response                 |\n",
    "| `patch_cratedb_sql()`       | Fixes interval/date syntax to be compatible with CrateDB                    |\n",
    "| `detect_manual_intent()`    | Uses keyword heuristics to decide if a manual is needed                     |\n",
    "| `extract_machine_id_from_query()` | Extracts machine ID (if any) from the user‚Äôs question                       |\n",
    "| `extract_anomaly_info()`    | Parses the manual for anomaly and emergency sections                        |\n",
    "| `explain_result_with_llm()`    | Uses the LLM to summarize telemetry results into plain language for end users                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe0cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Extract SQL queries and explanation from LLM response\n",
    "def extract_sql_blocks(response_text):\n",
    "    sql_blocks = re.findall(r\"```sql\\n(.*?)```\", response_text, flags=re.DOTALL)\n",
    "    sql1 = sql_blocks[0].strip() if len(sql_blocks) >= 1 else None\n",
    "    sql2 = sql_blocks[1].strip() if len(sql_blocks) >= 2 else None\n",
    "    answer_match = re.search(r\"Answer:\\s*(.*)\", response_text, flags=re.DOTALL)\n",
    "    answer = answer_match.group(1).strip() if answer_match else None\n",
    "    return sql1, sql2, answer\n",
    "\n",
    "# Patch SQL for CrateDB compatibility\n",
    "def patch_cratedb_sql(sql):\n",
    "    if not sql:\n",
    "        return sql\n",
    "    sql = re.sub(r\"INTERVAL\\s*'1\\s+week'\", \"INTERVAL '7 days'\", sql, flags=re.IGNORECASE)\n",
    "    sql = re.sub(r\"INTERVAL\\s*'1\\s+day'\", \"INTERVAL '1 days'\", sql, flags=re.IGNORECASE)\n",
    "    sql = re.sub(r\"\\bCURRENT_DATE\\b\", \"current_timestamp\", sql, flags=re.IGNORECASE)\n",
    "    sql = re.sub(\n",
    "        r\"DATE_TRUNC\\s*\\(\\s*'week'\\s*,\\s*CURRENT_TIMESTAMP\\s*\\)\", \n",
    "        \"date_trunc('week', current_timestamp)\", \n",
    "        sql, \n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    return sql\n",
    "\n",
    "# Detect whether the user is asking about manuals/anomalies\n",
    "def detect_manual_intent(query):\n",
    "    keywords = [\n",
    "        \"manual\", \"anomaly\", \"what should i do\", \"protocol\", \"emergency\", \"maintenance\",\n",
    "        \"overheating\", \"too hot\", \"too cold\", \"outside limits\", \"threshold\", \"limit\", \"safe\"\n",
    "    ]\n",
    "    return any(keyword in query.lower() for keyword in keywords)\n",
    "\n",
    "# Extract machine ID from user query\n",
    "def extract_machine_id_from_query(query):\n",
    "    match = re.search(r\"machine\\s*(\\d+)\", query.lower())\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Extract anomaly + emergency sections from the manual\n",
    "def extract_anomaly_info(manual_text):\n",
    "    anomaly_section = re.search(r\"\\*\\*Anomaly Detection:\\*\\*(.*?)---\", manual_text, re.DOTALL)\n",
    "    emergency_section = re.search(r\"\\*\\*Emergency Protocol:\\*\\*(.*?)---\", manual_text, re.DOTALL)\n",
    "    anomaly = anomaly_section.group(1).strip() if anomaly_section else \"No anomaly info found.\"\n",
    "    emergency = emergency_section.group(1).strip() if emergency_section else \"No emergency protocol found.\"\n",
    "    return anomaly, emergency\n",
    "\n",
    "# Use LLM to explain telemetry results in plain language\n",
    "def explain_result_with_llm(question, result_table):\n",
    "    if result_table is None or result_table.empty:\n",
    "        return \"No data available to generate explanation.\"\n",
    "    try:\n",
    "        result_text = result_table.to_string(index=False)\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant explaining CrateDB telemetry results.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Question: {question}\\n\\nResult:\\n{result_text}\\n\\nPlease summarize this in plain language.\"}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Failed to explain result: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591865cd",
   "metadata": {},
   "source": [
    "#### CrateDB Data Fetchers\n",
    "\n",
    "These functions handle:\n",
    "- Fetching schema info from CrateDB (for dynamic table structure awareness)\n",
    "- Fetching a machine‚Äôs manual from the machine_manuals table\n",
    "\n",
    "**Function Responsibility Table**\n",
    "\n",
    "| Function                     | Description                                                                 |\n",
    "|-----------------------------|-----------------------------------------------------------------------------|\n",
    "| `fetch_table_schema()`      | Fetches and formats schema metadata from CrateDB using `information_schema` |\n",
    "| `fetch_machine_manual()`    | Retrieves the machine's manual from CrateDB based on ID                     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d42829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table schema (columns and types) from CrateDB\n",
    "def fetch_table_schema(table_name):\n",
    "    query = f\"\"\"\n",
    "    SELECT column_name, data_type\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_name = '{table_name}'\n",
    "    ORDER BY ordinal_position\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_sql(query, con=engine)\n",
    "        schema_text = f\"Table: {table_name}\\nColumns:\\n\"\n",
    "        for _, row in df.iterrows():\n",
    "            schema_text += f\"- {row['column_name']} ({row['data_type']})\\n\"\n",
    "        return schema_text\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching schema for table '{table_name}':\", e)\n",
    "        return f\"Error fetching schema for {table_name}\"\n",
    "\n",
    "# Fetch the full machine manual from the DB\n",
    "def fetch_machine_manual(machine_id):\n",
    "    query = f\"SELECT manual FROM machine_manuals WHERE machine_id = {machine_id};\"\n",
    "    try:\n",
    "        df = pd.read_sql(query, con=engine)\n",
    "        if not df.empty:\n",
    "            return df.iloc[0]['manual']\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching manual for machine {machine_id}:\", e)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0831150a",
   "metadata": {},
   "source": [
    "#### get_combined_answer()\n",
    "\n",
    "| Function                     | Description                                                                 |\n",
    "|-----------------------------|-----------------------------------------------------------------------------|\n",
    "| `get_combined_answer()`     | Main orchestrator: prompts LLM, fetches data, and generates final answer    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2112a673",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong> Detailed Walkthrough of get_combined_answer() </strong></summary>\n",
    "\n",
    "##### Step 1: Fetch Table Schemas Dynamically\n",
    "``` python\n",
    "schema_motor = fetch_table_schema(\"motor_readings\")\n",
    "schema_manual = fetch_table_schema(\"machine_manuals\")\n",
    "```\n",
    "\n",
    "Goal:\n",
    "Fetches the latest schema for each relevant CrateDB table to include in the LLM prompt. This ensures the model always has accurate knowledge of the database structure, including any recent changes (e.g., new columns or types).\n",
    "\n",
    "##### Step 2: Analyze Question to Extract Context\n",
    "``` python\n",
    "machine_id = extract_machine_id_from_query(question)\n",
    "needs_manual = detect_manual_intent(question)\n",
    "```\n",
    "\n",
    "Goal:\n",
    "Parses the user‚Äôs question to determine:\n",
    "- Whether the user is referring to a specific machine (by ID).\n",
    "- Whether the user is asking for maintenance or anomaly-related help, which would require accessing the manual.\n",
    "\n",
    "\n",
    "##### Step 3: Optionally load manual and extract anomaly/emergency info\n",
    "\n",
    "``` python\n",
    "if needs_manual and machine_id is not None:\n",
    "    ...\n",
    "```\n",
    "\n",
    "Goal:\n",
    "If the question is about anomalies or maintenance, retrieve the corresponding machine manual and extract:\n",
    "- Anomaly detection rules\n",
    "- Emergency procedures\n",
    "\n",
    "This information will later be added to the LLM prompt to enrich the model‚Äôs context.\n",
    "\n",
    "##### Step 4: Build the Prompt for the LLM\n",
    "``` python\n",
    "prompt = f'''\n",
    "You are a CrateDB data assistant. Your job is to answer questions using telemetry data and machine manuals.\n",
    "\n",
    "Tables:\n",
    "{schema_motor}\n",
    "{schema_manual}\n",
    "\n",
    "{manual_context}\n",
    "\n",
    "Instructions:\n",
    "- For telemetry questions (e.g., performance metrics), generate SQL and explain the result.\n",
    "- For manual-related queries, summarize anomaly and emergency procedures using the context above.\n",
    "- If the question involves conditions (e.g., overheating, excessive vibration), \n",
    "  retrieve **both telemetry and manual**. Compare telemetry values against safe thresholds.\n",
    "- Use the following format:\n",
    "\n",
    "---\n",
    "SQL 1:\n",
    "<SQL for telemetry>\n",
    "\n",
    "SQL 2:\n",
    "<SQL for manual if needed>\n",
    "\n",
    "---\n",
    "Answer:\n",
    "<your explanation>\n",
    "'''\n",
    "```\n",
    "\n",
    "| **Prompt Section**                      | **Purpose** |\n",
    "|----------------------------------------|-------------|\n",
    "| `You are a CrateDB data assistant...`  | Defines the role of the LLM as a data-savvy assistant with access to CrateDB telemetry and machine manuals. Sets the tone and context for responses. |\n",
    "| `Tables:\\n{schema_motor}\\n{schema_manual}` | Dynamically injects the actual schema for the telemetry and manual tables. Enables the LLM to construct SQL queries using valid columns and data types. |\n",
    "| `{manual_context}`                     | Inserts guidance from the machine manual if the question indicates the user is looking for help related to anomalies, emergencies, or maintenance. This ensures the LLM can use real-world thresholds in its response. |\n",
    "| `Instructions:`                        | Directs the LLM how to respond to the user: when to generate SQL (telemetry), when to reference the manual, and how to combine the two if needed. |\n",
    "| `Use the following format:`            | Tells the model to respond in a consistent structure so downstream code can parse and present the result cleanly. |\n",
    "| `--- SQL 1: ... SQL 2: ... Answer:`    | Defines the output layout. `SQL 1` for telemetry queries, `SQL 2` for manuals if needed, and a natural language `Answer` summarizing the findings. |\n",
    "\n",
    "##### Step 5: Query the LLM\n",
    "\n",
    "``` python\n",
    "response = openai_client.chat.completions.create(...)\n",
    "```\n",
    "\n",
    "Goal:\n",
    "Send the structured prompt and user question to the LLM. The expected output should include:\n",
    "- One or two SQL queries\n",
    "- A natural language explanation of the result\n",
    "\n",
    "##### Step 6: Parse the LLM Output\n",
    "``` python\n",
    "parsed_sql1, parsed_sql2, answer = extract_sql_blocks(output)\n",
    "```\n",
    "\n",
    "Goal:\n",
    "Separates the LLM‚Äôs output into:\n",
    "- SQL 1: Main telemetry query\n",
    "- SQL 2: Optional manual query\n",
    "- Answer: Suggested explanation from the LLM\n",
    "\n",
    "Also applies cleanup using `patch_cratedb_sql()` to fix syntax issues CrateDB might not accept (e.g., CURRENT_DATE - INTERVAL '1 week').\n",
    "\n",
    "##### Step 7: Execute SQL Queries\n",
    "``` python\n",
    "df1 = pd.read_sql(sql1, con=engine)  # if present\n",
    "df2 = pd.read_sql(sql2, con=engine)  # if present\n",
    "```\n",
    "\n",
    "Goal:\n",
    "Run the SQL statements generated by the LLM against CrateDB and capture the results as pandas DataFrames.\n",
    "\n",
    "##### Step 8: Construct the Final Natural Language Answer\n",
    "``` python\n",
    "if needs_manual and anomaly_text:\n",
    "    final_answer = ...\n",
    "elif df1 is not None:\n",
    "    final_answer = explain_result_with_llm(question, df1)\n",
    "else:\n",
    "    final_answer = ...\n",
    "```\n",
    "\n",
    "Goal:\n",
    "Based on what was returned:\n",
    "- If it‚Äôs a manual question ‚Üí use structured anomaly/emergency info.\n",
    "- If it‚Äôs a telemetry question with valid data ‚Üí summarize with explain_result_with_llm().\n",
    "- Otherwise, fall back to the LLM‚Äôs explanation or return a generic message.\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d328af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_answer(question):\n",
    "    # Step 1: Fetch table schemas dynamically\n",
    "    schema_motor = fetch_table_schema(\"motor_readings\")\n",
    "    schema_manual = fetch_table_schema(\"machine_manuals\")\n",
    "\n",
    "    # Step 2: Analyze question to extract context\n",
    "    machine_id = extract_machine_id_from_query(question)\n",
    "    needs_manual = detect_manual_intent(question)\n",
    "\n",
    "    # Step 3: Optionally load manual and extract anomaly/emergency info\n",
    "    manual_context = \"\"\n",
    "    anomaly_text, emergency_text = None, None\n",
    "    sql2 = None  # placeholder for optional manual SQL\n",
    "\n",
    "    if needs_manual and machine_id is not None:\n",
    "        manual = fetch_machine_manual(machine_id)\n",
    "        if manual:\n",
    "            anomaly_text, emergency_text = extract_anomaly_info(manual)\n",
    "            manual_context = f'''\n",
    "Manual Guidance for Machine {machine_id}:\n",
    "--- Anomaly Detection ---\n",
    "{anomaly_text}\n",
    "--- Emergency Protocol ---\n",
    "{emergency_text}\n",
    "'''\n",
    "            sql2 = f\"SELECT manual FROM machine_manuals WHERE machine_id = {machine_id};\"\n",
    "\n",
    "    # Step 4: Build LLM prompt\n",
    "    prompt = f'''\n",
    "You are a CrateDB data assistant. Your job is to answer questions using telemetry data and machine manuals.\n",
    "\n",
    "Tables:\n",
    "{schema_motor}\n",
    "{schema_manual}\n",
    "\n",
    "{manual_context}\n",
    "\n",
    "Instructions:\n",
    "- For telemetry questions (e.g., performance metrics), generate SQL and explain the result.\n",
    "- For manual-related queries, summarize anomaly and emergency procedures using the context above.\n",
    "- If the question involves conditions (e.g., overheating, excessive vibration), \n",
    "  retrieve **both telemetry and manual**. Compare telemetry values against safe thresholds.\n",
    "- Use the following format:\n",
    "\n",
    "---\n",
    "SQL 1:\n",
    "<SQL for telemetry>\n",
    "\n",
    "SQL 2:\n",
    "<SQL for manual if needed>\n",
    "\n",
    "---\n",
    "Answer:\n",
    "<your explanation>\n",
    "'''\n",
    "\n",
    "    # Step 5: Query the LLM with the prompt and question\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant working with CrateDB telemetry and manuals.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt + f\"\\n\\nUser question: {question}\"}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=700\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message.content.strip()\n",
    "\n",
    "    # Step 6: Parse and clean LLM output\n",
    "    parsed_sql1, parsed_sql2, answer = extract_sql_blocks(output)\n",
    "    sql1 = patch_cratedb_sql(parsed_sql1) if parsed_sql1 else None\n",
    "    sql2 = patch_cratedb_sql(parsed_sql2) if parsed_sql2 else sql2\n",
    "\n",
    "    # Step 7: Execute queries\n",
    "    df1, df2 = None, None\n",
    "\n",
    "    try:\n",
    "        if sql1:\n",
    "            df1 = pd.read_sql(sql1, con=engine)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to execute SQL 1:\", sql1)\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        if sql2:\n",
    "            df2 = pd.read_sql(sql2, con=engine)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to execute SQL 2:\", sql2)\n",
    "        print(e)\n",
    "\n",
    "    # Step 8: Construct final natural language explanation\n",
    "    if needs_manual and anomaly_text and emergency_text:\n",
    "        final_answer = f'''\n",
    "üìå Manual Guidance for Machine {machine_id}\n",
    "\n",
    "--- Anomaly Detection ---\n",
    "{anomaly_text}\n",
    "\n",
    "--- Emergency Protocol ---\n",
    "{emergency_text}\n",
    "'''.strip()\n",
    "    elif df1 is not None and not df1.empty:\n",
    "        final_answer = explain_result_with_llm(question, df1)\n",
    "    else:\n",
    "        final_answer = answer or \"No answer could be generated.\"\n",
    "\n",
    "    return sql1, sql2, df1, df2, final_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc65dc9e",
   "metadata": {},
   "source": [
    "### Ask a Question (Natural Language Interface)\n",
    "\n",
    "This is your main interaction point with the assistant. Just type in a natural language question, and the assistant will:\n",
    "\t‚Ä¢\tAnalyze your query\n",
    "\t‚Ä¢\tDecide if telemetry data or manual context is needed\n",
    "\t‚Ä¢\tGenerate and run SQL queries\n",
    "\t‚Ä¢\tExplain the results in plain language\n",
    "\t‚Ä¢\tOptionally summarize emergency protocols from manuals\n",
    "\n",
    "\n",
    "Here are some example queries and what kind of answers you can expect:\n",
    "\n",
    "| üí¨ Question                                                                 | üß† Assistant Behavior                                                            |\n",
    "|-----------------------------------------------------------------------------|----------------------------------------------------------------------------------|\n",
    "| `What was the average temperature for machine 3 last week?`                  | Retrieves average temperature from telemetry and explains the result.           |\n",
    "| `Is machine 4 overheating?`                                                  | Checks the latest temperature and compares it with manual thresholds if present.|\n",
    "| `What should I do if machine 2 has an anomaly?`                              | Loads the manual for machine 2 and summarizes anomaly and emergency protocols.  |\n",
    "| `Give me the max and min vibration for machine 6 when RPM > 1600`            | Executes a filtered SQL query and summarizes the max/min vibration values.      |\n",
    "| `Show me the maintenance steps for machine 1`                               | Extracts and summarizes the maintenance section from the manual.                |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03bb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a combined question\n",
    "# Example questions:\n",
    "# \n",
    "# What was the average temperature for machine 3 last week?\n",
    "# Is machine 4 overheating?\n",
    "# What should I do if machine 2 has an anomaly?\n",
    "# Give me the max and min vibration for machine 6 when RPM > 1600.\n",
    "# Show me the maintenance steps for machine 1.\n",
    "\n",
    "# question = \"Type your question here and push ‚ñ∂Ô∏è\"\n",
    "question = \"Give me the max and min vibration for machine 6 when RPM > 1600\"\n",
    "\n",
    "sql1, sql2, df1, df2, final_answer = get_combined_answer(question)\n",
    "\n",
    "output = []\n",
    "\n",
    "output.append(\"üß† SQL 1 (telemetry):\")\n",
    "output.append(sql1.strip() if sql1 else \"‚Äî\")\n",
    "\n",
    "output.append(\"\\nüìò SQL 2 (manual):\")\n",
    "output.append(sql2.strip() if sql2 else \"‚Äî\")\n",
    "\n",
    "if df1 is not None and not df1.empty:\n",
    "    output.append(\"\\nüîç Telemetry Result:\")\n",
    "    output.append(df1.to_string(index=False))\n",
    "else:\n",
    "    output.append(\"\\nüîç No telemetry data returned.\")\n",
    "\n",
    "if df2 is not None and not df2.empty:\n",
    "    output.append(\"\\nüìö Manual Result:\")\n",
    "    output.append(df2.to_string(index=False))\n",
    "else:\n",
    "    output.append(\"\\nüìö No manual data returned.\")\n",
    "\n",
    "output.append(\"\\nüßæ Final Answer:\")\n",
    "output.append(final_answer.strip() if final_answer else \"No answer returned.\")\n",
    "\n",
    "# Join and print once\n",
    "print(\"\\n\".join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98110e",
   "metadata": {},
   "source": [
    "--- \n",
    "## Step 8: Recap & Lessons Learned\n",
    "\n",
    "Congratulations on completing the Timeseries QA with LLMs & Manuals workshop!\n",
    "Let‚Äôs wrap things up with a quick recap of what we‚Äôve achieved and the key takeaways.\n",
    "\n",
    "### Workshop Recap\n",
    "\n",
    "Over the course of this notebook, you:\n",
    "- Set up your environment and connected to CrateDB, a powerful distributed SQL database optimized for time-series data.\n",
    "- Generated and loaded synthetic telemetry data simulating real-world sensor readings from industrial machines.\n",
    "- Explored the data using SQL and previewed time coverage and machine behavior.\n",
    "- Built a natural language interface with an LLM to convert plain English into CrateDB-compatible SQL queries.\n",
    "- Visualized time-series data directly from natural language questions, bringing clarity to trends, outliers, and anomalies.\n",
    "- Generated structured machine manuals, complete with thresholds, anomaly rules, and emergency procedures.\n",
    "- Merged telemetry with manual context, allowing a single question to yield data-driven insights and operational guidance.\n",
    "\n",
    "### Key Lessons Learned\n",
    "\n",
    "| Skill                   | What You Practiced                                                                 |\n",
    "|---------------------------|----------------------------------------------------------------------------------------|\n",
    "| **LLM Prompt Engineering**| How to design system prompts and templates that turn natural language into SQL.        |\n",
    "| **Table-Augmented Generation (TAG)** | Augmenting LLMs with live table schemas to improve query accuracy.                   |\n",
    "| **Time-Series Analysis**  | Using SQL and pandas to inspect, filter, and visualize sensor data over time.         |\n",
    "| **CrateDB Features**      | Leveraging a scalable time-series database with SQL support.     |\n",
    "| **RAG-like Patterns**     | Combining structured telemetry with unstructured manuals for richer QA experiences.   |\n",
    "\n",
    "\n",
    "üôå Thanks for Participating!\n",
    "\n",
    "We hope this workshop has inspired you to combine structured data, unstructured manuals, and language models in powerful new ways."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
